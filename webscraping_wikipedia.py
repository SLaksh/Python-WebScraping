# -*- coding: utf-8 -*-
"""WebScraping-wikipedia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17wLZ83MmH2KemKeur5URYwCuuh-MTfEH
"""

!pip install requests

!pip install beautifulsoup4

from bs4 import BeautifulSoup
#import requests library
import requests
#the website URL
url_link = "https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States"
result = requests.get(url_link).text
doc = BeautifulSoup(result, "html.parser")

print(doc.prettify())

"""# **FIND ELEMENTS BY ID:**"""

res = doc.find(id = "content")
print(res)

"""# **FIND ELEMENTS BY CLASS NAME**"""

heading = res.find(class_ = "firstHeading")
print(heading)

"""# **EXTRACTING TEXT FROM HTML ELEMENTS**"""

print(heading.text)



"""# **ACCESSING THE NESTED TAGS:**

**Trying to find all the h2 tags in the "<main- element with id=”content”.**
"""

res = doc.find(id = "content")
for ele in res:
  print(res.find("h2"))

"""# **SEARCHING USING STRING(TEXT):**"""

res = doc.find_all(text = "California")
print(res)

"""# **SEARCH BY PASSING A LIST**"""

res=doc.find_all(["a","p","div"])
print(res)

"""# **SEARCH USING A REGULAR EXPRESSION**"""

import re

for str in doc.find_all(text = re.compile("1788")):
  print(str)

"""**If you want to get only a limited number of results, you can do so by using limit.**"""

for str in doc.find_all(text = re.compile("1788"), limit = 2):
  print(str)

"""# **SEARCH USING CSS SELECTORS**"""

print(doc.select("title"))

print(doc.select("html head title"))

"""# **The real code**"""

from bs4 import BeautifulSoup
#import requests library
import requests
#the website url
url_link="https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States"
result=requests.get(url_link).text
print(result)
doc=BeautifulSoup(result, "html.parser")

"""**We use the BeautifulSoup object created above and collect the required table data by using the class name**"""

my_table=doc.find("table", class_="wikitable sortable plainrowheaders")
print(my_table)

"""**We then extract all the !th tags in our table and finally get the text inside the !a> tags.**"""

th_tags = my_table.find_all('th')
names = []
for elem in th_tags:
  #finding the < a > tag
  a_links = elem.find_all("a")
  print(a_links)
#getting the text inside the < a > tag
for i in a_links:
  names.append(i.string)
print(names)

final_list = names[9: ]
states = []
for str in final_list:
  if len(str) > 3:
    states.append(str)
print(states)

divs = my_table.find_all("div")
pop = []
for i in divs:
  pop.append(i.string)
print(pop)

pop_final = []
for i in pop:
  if len(i) > 3:
    pop_final.append(i)
print(pop_final)

import pandas as pd
df = pd.DataFrame()
df['state'] = states
df['population'] = pop_final

print(df)